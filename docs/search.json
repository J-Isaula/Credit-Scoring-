[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Credit Scoring",
    "section": "",
    "text": "Welcome\nBienvenidos, en este artículo te presento algunos modelos tradicionales, modernos y conceptos fundamentales para que te encamines al mundo del Credit Scoring. Existen algunas definiciones para Credit Scoring; sin embargo, en este trabajo, se considera a un credit scoring como un conjunto de metodologías que permitan evidenciar la probabilidad que un cliente cumpla o no con sus obligaciones, a partir de la información que se conozca del mismo. Estos modelos tienen muchas funciones dentro del ciclo de vida de un crédito que comprende el otorgamiento, seguimiento, cobranza y recuperación; sin embargo, este artículo se enfocará en las metodologías que sirven de apoyo, en la toma de decisiones del proceso de otorgamiento de créditos; tales metodologías deben permitir medir los riesgos de los potenciales clientes, a fin de precisar quienen podrían ser sujetos de crédito, estableciendo variables significativas que ayudan a identificar los individuos cuyo riesgo se ajuste al perfil de riesgo de la institución.\nWelcome, in this article we present some traditional and modern models and fundamental concepts to guide you into the world of Credit Scoring. There are a few definitions for Credit Scoring; However, in this work, credit scoring is considereded as a set of methodologies that allow us to demonstrate the probability that a client meets or does not comply with its obligations, based on the information known about it. These models have many functions within the life cycle of a loan that includes granting, monitoring, collection and recovery; However, this article will focus on the methodologies that serve as support in decision making in the credit granting process; such methodologies must allow measuring the risks of potential clients, in order to specify who could be subject to credit, establishing significant variables that help identify individuals whose risk fits the institution’s risk profile.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "En el proceso de otorgamiento de créditos, una institución no puede tomar decisiones a partir de su juicio de experto para cada una de las solicitudes recibidas, pues con el aumento en el número de solicitantes y la competencia intensa en la industria crediticia, este método no puede satisfacer las demandas en los aspectos economicos y de eficiencia (Lean Yu 2008); sino que intentará adoptar sistemas de calificación de créditos para facilitar y acelerar los procesos en la toma de decisiones. Por tal motivo, nace el concepto de modelos de Credit Scoring o modelos de calificación de créditos (Samsul Islam 2009).\nMuchos algoritmos son usados para la construcción de un credit scoring, sin embargo, cada vez se deberá buscar alternativas más efectivas para tomar decisiones más precisas, por ejemplo, las redes neuronales (Samsul Islam 2009).\nSon muchos los factores que pueden incidir en el crecimiento de la cartera vencida o el incremento de la mora de una cartera, como malas prácticas en la concesión de créditos, metas de crédito agresivas por parte de la institución, deterioro del empleo, recesión ecónomica, etc. Sin embargo, el anterior escenario evidencia la necesidad de contar con nuevas herramientas para la gestión de riesgo de crédito que ayuden a minimizar la probabilidad de pérdida de una institución, buscando alcanzar la eficiencia de la gestión de riesgos a partir de mejores herramientas estadísticas e informáticas.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#section",
    "href": "preface.html#section",
    "title": "Preface",
    "section": "",
    "text": "Lean Yu, Kin Keung Lai, Shouyang Wang. 2008. Bio-Inspired Credit Risk Analysis: Computational Intelligence with Support Vector Machines. Springer Link.\n\n\nSamsul Islam, Fei Li, Lin Zhou. 2009. Application of Artificial Intelligence (Artificial Neural Network) to Assess Credit Risk: A Predictive Model for Credit Card Scoring. Springer Link.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "modelos.html",
    "href": "modelos.html",
    "title": "1  Modelos Credit Scoring",
    "section": "",
    "text": "1.1 Modelo de Regresión Logística - Logit\nLos modelos logit pertenecen al grupo jde modelos de regresión con respuesta cualitativa, en este caso binaria; mientras que las variables independientes pueden ser cualitativas o cuantitativas, o una mezcla de ambas (Flórez 2002).\nEl modelo está basado en una función de distribución logística, cuya estructura se presenta a continuación:\n\\[\nP(Y = 1 | X) = F(\\textbf{Z}) = \\frac{e^{\\textbf{Z}}}{1 + e^{\\textbf{Z}}}, \\hspace{1cm} -\\infty &lt; z &lt;\\infty,\\hspace{1cm} (2)\n\\]\ncon \\(z = \\textbf{X}^T\\beta = \\beta_0 + \\beta_1x_1 + . . . + \\beta_nx_n\\).\ndonde:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Credit Scoring</span>"
    ]
  },
  {
    "objectID": "modelos.html#modelo-de-regresión-logística---logit",
    "href": "modelos.html#modelo-de-regresión-logística---logit",
    "title": "1  Modelos Credit Scoring",
    "section": "",
    "text": "Fuente: Flores y Rincón (2002, 128)\n\n\n\n\n$ $ Es la variable dependiente, binaria, que no puede tomar dos posibles valores, que se etiquetarán con 0 (cliente malo) y 1 (cliente bueno).\n\\(\\textbf{X:}\\) Es el conjunto de \\(n\\) variables independientes \\((x_1, x_2, . . . , x_n)\\) relacionadas con la información propia del solicitante, tomadas con el fin de explicar y/o predecir el valor de \\(\\textbf{Y}\\).\n\\(F(\\textbf{Z}):\\) Es la función de probabilidad, que depende de un vector de parámetros \\(\\beta = (\\beta_0, \\beta_1, . . . , \\beta_n)\\), que permitirán relacionar las variables independientes \\(\\textbf{X}\\), con la dependiente \\(\\textbf{Y}\\). Esta función tiene un rango entre \\([0,1]\\) y se conoce como función de distribución logística.\nEl objetivo del modelo es encontrar los coeficientes \\(\\beta\\) que mejor se ajustan a la expresión \\(P(Y = 1|X)\\).\n\n\n1.1.1 Estimación de los parámetros del modelo logit\nLa estimación de los coeficientes \\(\\beta\\) puede realizarse a partir del método de máxima verosimilitud (Gujarati 2005).\nSupóngase que se cuenta con un conjunto de \\(k\\) individuos; de tal forma que, catalogarles como buenos o malos clientes será definido por la variable \\(Y_i\\), considerando \\(i = 1, . . . , k\\).\nEn vista que cada \\(Y_i\\) es una variable aleatoria de Bernoulli, por tomar dos valores, 0 o 1, podemos expresar la probabilidad que suceda uno u otro evento, como sigue:\n\\[\n\\begin{eqnarray}\nP(Y_i = 1) &=& P_i\\\\[0.2cm]\nP(Y_i = 0) &=& 1 - P_i\n\\end{eqnarray}\n\\]\nsu función de probabilidad será:\n\\[\nf_i(Y_i) = P_i^{Y_i}\\times (1 - P_i)^{1-Y_i}, \\hspace{1cm} i = 1, . . . , k\\hspace{1cm} (3)\n\\]\nEs decir, la función \\(f_i(Y_i)\\) denota la probabilidad de \\(Y_i = 0~ o~ 1\\).\nComo cada observación es independiente, la probabilidad conjunta de observar los \\(k\\) valores de la variable \\(Y\\), se expresa como:\n\\[\nf(Y_1, Y_2, . . . , Y_k) = \\prod_{i=1}^{k} f_i(Y_i) = \\prod_{i=1}^{k} P_i^{Y_i}\n\\times (1- P_i)^{1-Y_i}\\hspace{1cm}(4)\\]\nA está probabilidad conjunta se le conoce como función de verosimilitud. Al tomar el logaritmo de está función se tiene:\n\\[\n\\begin{eqnarray}\n\\ln(f(Y_1, Y_2, . . . , Y_k)) &=& \\left[Y_i\\ln P_i + (1 - P_i)\\ln(1 - P_i)\\right]\\\\[0.2cm]\n&=& \\sum_{i=1}^{k} \\left[Y_i\\ln P_i - Y_i\\ln(1-P_i) + \\ln(1 - P_i)\\right]\\\\[0.2cm]\n&=& \\sum_{i=1}^{k} \\left[Y_i\\ln\\left(\\frac{P_i}{1 - P_i}\\right)\\right] + \\sum_{i=1}^{k}\\ln(1 - P_i)\\hspace{1.5cm} (5)\n\\end{eqnarray}\n\\]\nTal como se expuso en ecuación \\((2)\\), la probabilidad de que un individuo sea un buen o mal cliente es representado por:\n\\[\nP_i = \\frac{e^{X_i^T\\beta}}{1 + e^{X_i^T\\beta}} \\hspace{1cm} (6)\n\\]\nDe aquí se puede, facilmente, demostrar que:\n\\[\n1 - P_i = \\frac{1}{1 + e^{X_i^T\\beta}}\\hspace{1cm}(7)\n\\]\nDe igual forma,\n\\[\n\\ln\\left(\\frac{P_i}{1-P_i}\\right) = X_i^T\\beta\\hspace{1cm} (8)\n\\]\nConsiderando \\((7)\\) y \\((8)\\) en \\((5)\\) , se puede expresar el logaritmo de la función de verosimilitud, como sigue\n\\[\n\\ln\\left(f(Y_1, . . . , Y_k)\\right) = \\sum_{i=1}^{k}Y_i(X_i^T\\beta) - \\sum_{i=1}^{k}\\ln\\left(1 + e^{X_i^T\\beta}\\right)\\hspace{1cm} (9)\n\\]\nPodemos observar que \\((9)\\) es una función que depende de los coeficientes \\(\\beta\\), pues \\(Y_i\\) y \\(X_i\\) se conocen.\nEl método de máxima verosimilitud consiste en maximizar la expresión \\((9)\\), para buscar la máxima capacidad predictiva. Para esto se deriva parcialmente, respecto a cada una de las incógnitas; es decir, respecto a cada \\(\\beta_j\\), con \\(j = 1, . . . , n\\). Obteniendo un sistema de \\(n\\) ecuaciones no lineales, que deberán resolverse por procedimientos numéricos.\nUna vez obtenidos los \\(\\beta\\) se verifica que en verdad maximicen la función de verosimilitud a partir de la condición de maximización de segundo orden. Luego de este proceso, se obtiene los coeficientes, necesarios para estimar la probabilidad de incumplimiento de un individuo, a partir de la ecuación \\((2)\\).\n\n\n1.1.2 Interpretación coeficientes de una regresión logística\nUna de las razones, por las cuales se utiliza con mayor frecuencia un modelo de regresión logística es que su interpretación es relativamente sencilla. Para apreciar este beneficio, es de ayuda entender el significado de odds. Tal como lo expresa (Allison 2012) muchas personas consideran a una probabilidad como la forma natural de cuantificar que un evento ocurra, considerando valores que se mueven entre 0 y 1. Sin embargo, existen otras formas de representar un cambio natural en algún evento, esto son los odds ratios.\nEl mismo autor, define los odds, como la relación entre el número esperado de veces que un evento ocurra y el número esperado de veces que este no ocurra. De esta forma, la relación entre el odds y la probabilidad es:\n\\[\nOdds = \\frac{probabilidad~que~un~evento~ocurra}{1 - Probabilidad~que~un~evento~ocurra}\n\\]\nEsta expresión tiene relevancia en un modelo de regresión logística, pues si se considera \\((6)\\) y \\((7)\\) se tienen,\n\\[\n\\frac{P_i}{1- P_i} = \\frac{\\frac{e^{X_i^T\\beta}}{1 + e^{X_i^T\\beta}}}{\\frac{1}{1 + e^{X_i^T\\beta}}} = e^{X_i^T\\beta}\\hspace{1cm} (10)\n\\]\nA esta expresión se la considera como transformación logit de la probabilidad \\(P_i\\), cuya parte izquierda es una razón de probabilidades u odds (Flórez 2002). Al considerar el logaritmo natural en \\((10)\\) se obtiene el logaritmo de la razón de proabilidades conocido como logit y es por este término que al modelo de regresión logística se lo conoce, también, como modelo logit. Así, se llega a la ecuación \\((8)\\).\n\\[\nL = \\ln\\left(\\frac{P_i}{1 - P_i}\\right) = X_i^T\\beta = \\beta_0 + \\beta_1x_1 + . . . + \\beta_nx_n\\hspace{1cm}(11)\n\\]\nDe esta forma, la interpretación del modelo está dada por la expresión logit (L); por ejemplo, \\(\\beta_2\\) mide el cambio en \\(L\\) ocasionado por un cambio unitario en \\(x_2\\), suponiendo constante el resto de variables explicativas (Gujarati 2005).\nLa interpretación del modelo también puede darse a partir del odds ratio, la cual es una medida de la magnitud de asociación entre dos variables; en este caso, cada una de las independientes con la dependiente. Un odds ratio mayor a 1, muestra que existe una relación positiva o directa entre las dos variables, mientras que un odds ratio menor a 1, establece una relación negativa o inversa. Cuando el odds ratio es igual a 1, significa que no existe una relación entre las mismas (Velasco 1996).\nEl odds ratio puede calcularse a partir de la estimación de los parámetros del modelo\n\\[\nodds~ratio = e^\\beta\\hspace{6cm}(12)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Credit Scoring</span>"
    ]
  },
  {
    "objectID": "modelos.html#modelo-de-redes-neuronales",
    "href": "modelos.html#modelo-de-redes-neuronales",
    "title": "1  Modelos Credit Scoring",
    "section": "1.2 Modelo de Redes Neuronales",
    "text": "1.2 Modelo de Redes Neuronales\nLas redes neuronales artificiales (RNA) son modelos matemáticos computacionales que intentan imitar el funcionamiento del cerebro de la forma como este procesa la información. Se cataloga dentro de las técnicas no paramétricas de credit scoring, como sistemas con la capacidad de aprender a través de entrenamiento, también conocido como la interpretación que ellas hacen de la información que reciben (BAHAMÓN 2013).\n\n1.2.1 Modelo Biológico\n\nLa figura muestra un tipo común de neurona biológica, que está compuesta principalmente por:\n\nUn cuerpo central, que contiene el núcleo celular, denominado Soma.\nLa conexión entre neuoronas se establece a partir de una prolongación del Soma, llamada Axón, que también se ramifica en su extremo final para establecer conexión con ontras neuronas, estas ramificaciones son conocidas como terminales axónicos.\nLas dendritas que son ramificaciones del cuerpo central, con las cuales se logra la conexión sináptica.\n\nSe estima que alrededor de cien mil millones de neuronas son las que conforman el sistema nervioso; estas se diferencian del resto de células vivas en el hecho que poseen capacidad de comunicarse.\nEn general, las dendritas y el Soma reciben las señales de entrada, el cuerpo celular las combina y emite señales de salida; a continuación, el Axón transmite esta señal a sus terminales, que se encargan de distribuir la información a otro conjunto de neuronas (Brío 2002).\nUn aspecto muy importante en el proceso e comunicación entre neuronas es el término conocido como sinapsis. Brio y Molina (2002) lo definen como la unión entre dos neuronas, en el proceso de generación y transmisión de la señal nerviosa.\n\n\n1.2.2 Elementos de una red neuronal artificial\nPara introducir los elementos de una red neuronal artificial, se hará uso de la siguiente figura, que cuenta con una sola neurona; es decir, una pequeña parte de un sistema de red neuronal artificial. Además, se puede evidenciar que esta tiene una forma similar a la neurona biológica de la figura anterior.\n\nSe puede observar en esta figura que se tiene un elemento central, llamado neurona artificial la cual recibe información del exterior o de otras neuronas. Las dendritas son la estructura a través de la cual la neurona artificial recibe información, que luego es procesada de acuerdo con la intensidad asignada al nexo entre la unión de las entradas y las neuronas; este nexo se denomina sinapsis y a la intensidad descrita se le conoce como peso sináptico \\((\\textbf{W})\\).\nLas redes neuronales intentan reproducir el comportamiento del cerebro, por lo cual, cualquier modelo de red neuronal consta de dispositivos elementales de proceso, denominados neuronas.\nLos elementos que constituyen a una neurona \\(z\\) son los siguientes:\n\nConjunto de entradas \\(x_i(t)\\), \\(i = 1, . . . , n\\): las cuales pueden ser binarias o continuas, dependiendo del tipo de modelo y aplicación.\nPesos sinápticos de la nuerona \\(z\\): catalogados como \\(w_{zi}\\), que representa la intensidad de interacción entre la entrada \\(i\\) y la neurona \\(z\\). Dependiendo de los pesos, se puede obtener la salida necesaria, considerando entradas específicas. Cuanto más grande sea el peso, más fuerte y relevante será el nodo de entrada.\nFunción de agregación también llamada regla de propagación: Se denomina función de agregación a aquella regla que relaciona las entradas y los pesos para obtener el valor de la señal postsináptica \\(h_z\\), conocido como potencial postsináptico: \\[h_z(t) = \\sigma_z(w_{zi},x_i(t))\\]\nLa función más habitual es lineal y consiste en la suma ponderada de las entradas con los pesos signápticos, \\[h_z(t) = \\sum_{i=1}^n w_{zi}x_i \\]\nDada una entrada positiva, si el peso también es positivo, entonces este tenderá a excitar a la neurona, si el peso es negativo, tenderá a inhibirla (Brío 2002).\nFunción de activación: La misma proporciona el estado de activación, en el tiempo \\(t\\), \\(a_z(t)\\), a partir del potencial postsináptico \\(h_z(t)\\) y del estado de activación anterior \\(a_z(t-1)\\). \\[a_z(t) = f_z(a_z(t-1), h_z(t))\\]\nSin embargo muchos modelos de redes neuronales consideran que el estado actual de la neurona (tiempo \\(t\\)) no depende de su estado anterior (Brío 2002), por lo cual \\[a_z(t) = f_z(h_z(t))\\]\nEn general se puede establecer dos estados posibles, reposo y excitado, a los cuales se les asigna un valor que puede ser continuo o discreto (González 2000).\n\nEn la mayor parte de modelos la función de activación \\(f(\\cdot)\\) es monótona creciente y continua. En el siguiente cuadro, se exponen las funciones de activación más usuales, en donde: \\(\\textbf{x}\\) representa el potencial postsináptico y el estado de activación.\n\nFunciones de activación usuales.\n\n\n\n\n\n\n\n\nFunción\nRango\n\n\n\n\nIdentidad\n\\[\ny = x\n\\]\n\\[\n[-\\infty, +\\infty]\n\\]\n\n\nEscalón\n\\[\ny = sign(x)\n\\]\n\\[\ny = H(x)\n\\]\n\\[\n{-1, +1}\n\\]\n\\[\n{0, +1}\n\\]\n\n\n\nSigmoidea\n\\[\ny = \\frac{1}{1 + e^-x}\n\\]\n\\[\ny = tgh(x)\n\\]\n\\[\n[0, +1]\n\\]\n\\[\n[-1, +1]\n\\]\n\n\nGaussiana\n\\[\ny = Ae^{-Bx^2}\n\\]\n\\[\n[0, +1]\n\\]\n\n\nSinusoidal\n\\[\ny = Asin(\\omega x + \\phi)\n\\]\n\\[\n[-1, +1]\n\\]\n\n\n\nMuchas veces se adiciona al grupo de pesos, un parámetro adicional \\(\\theta_z\\), el cual se resta del potencial postsináptico, y representa características propias de la neurona, de tal forma que no es igual en todas ellas.\n\nPor ejemplo, en el caso de neuronas todo-nada, el parámetro representa el nivel mínimo que debe lograr el potencial postsináptico para que la neurona se active. De tal forma, el argumento de la función de activación se expresa de la siguiente forma \\[\\sum_{i=1}^n w_{zi}x_i - \\theta_z\\]\n\nFunción de salida: Es la función que proporciona la salida de la neurona \\(y_z(t)\\), que depende del estado de activación \\(a_z(t)\\). Por lo general la función de salida es la identidad \\((F(x) = x)\\) por lo cual la salida es considerada con el estado de activación de la neurona \\[y_z(t) = F_z(a_z(t)) = a_z(t)\\] Finalmente, el modelo neuronal que (Brío 2002) denomina como estándar queda como se muestra a continuación \\[y_z(t) = f_z(\\sum_{i=1}^n w_{zi}x_i - \\theta_z) = f_z(\\sum_{i=0}^n w_{zi}x_i)\\] con \\(w_{z0} = \\theta_z\\) y \\(x_0 = -1\\).\n\n\n\n1.2.3 Arquitectura de las redes neuronales\nEn la sección previa se mostroó los principales componentes de una red neuronal. A continuación, se expone las características de cada nodo de la red, así como la organización de esta.\nGeneralmente, se puede encontrar tres tipos de neuronas:\n\nLas que toman la información de entrada, de las fuentes externas de la red.\nLas que procesan la información y generan cualquier tipo de representación interna de la misma. A estos se los denomina unidades ocultas pues no tienen relación directa con la información de entrada o de salida.\nCuando ya se tiene procesada la información, esta pasa a los nodos de salida, los cuales dan una respuesta al sistema.\n\nLa distribución de estas neuronas está dada formando niveles o capas de un número determinado de neuronas cada una. Así, se puede determinar tres tipos de capas: de entrada, ocultas y de salida, conformadas por los tipos de neuronas ya descritas.\nEl número de capas ocultas puede estar entre cero 1 un número elevado y pueden estar interconectadas de diversas formas, estos dos aspectos determinan las distintas tipologías de redes neuronales.\nOtro aspecto importante en la arquitectura de una red neuronal es la forma en la que se realizan las conexiones entre las neuronas, es decir, la forma en la que las salidas de las nueronas están encaminadas para convertirse en las entradas de otras neuronas. Incluso se puede dar que la salida de un nodo sea la entrada de sí misma, llamandose a este tipo de conexión como auto recurrente.\n(González 2000) mencionan dos tipos de conexiones, propagación hacia atrás que es cuando las salidas de los nodos pueden conectarse con capas previas o del mismo nivel, incluso con si mismos. Y propagación hacia adelante, cuando la salida de los nodos se conecta únicamente con nodos de capas posteriores.\n\n\n\nEstructura de una red neuronal artificial multicapa.\n\n\nEs así, que la arquitectura de las redes neuronales se basa en la forma en que se organizan y disponen las neuronas formando capas más o menos alejadas de la entrada y salida de la red, tal como se muestra en la figura.\nEn general, no se cuenta con una regla que determine el número óptimo de neuronas ocultas que ayudan a resolver un problema; sino más bien, es a base de prueba y error, realizando cambios en el que se asume o reste el número de neuronas ocultas hasta alcanzar la estructura que mejor se ajuste a la solución de un problema dado (Tudela 2011).\nSe suele distinguir entre redes con una sola capa o un solo nivel de neuronas denominadas como redes monocapa y, con múltiples capas. Es así que, los principales parámetros de una red neuronal serían el número de capas, el número de neuronas en cada capa, el grado de conectividad y el tipo de conexión entre cada neurona (Carranza Bravo 2010).\n\n\n1.2.4 Modos de operación de una red neuronal\nSe considera dos tipos de operación en un sistema neuronal: el modo recuerdo o ejecución y el modo aprendizaje.\n\n1.2.4.1 Fase de aprendizaje\nSe tiene un especial interés en esta fase pues una de las principales características de una red neuronal es que son sistemas entrenables, es decir, son capaces de llevar a cabo un específico procesamiento aprendiendo de un grupo de patrones de aprendizaje o ejemplos.\nPuede definirse al aprendizaje como el proceso en el cual se modifica los pesos de la neurona en respuesta a la información de entrada. Tal como expresa (González 2000) en el proceso de aprendizaje se destruye, modifica y crea conexiones entre las neuronas; que una conexión se destruya signifca que su peso pasa a tener el valor de cero y que se cree significa que toma un valor diferente de cero.\nComo ya se mencionó, en el proceso de aprendizaje se modifican los pesos de las conexiones. Por lo cual, se puede establecer que la red neuronal ha terminado su fase de aprendizaje una vez que los pesos logren estabilidad en el tiempo. Generalmente, su modifica los pesos sinápticos siguiendo cierta regla de aprendizaje, que es construida a partir de una función de error. Este proceso es iterativo, es decir, los pesos van actualizándose una y otra vez hasta que la red neuronal logra un rendimiento deseado (Brío 2002).\nEs importante conocer las reglas de aprendizaje de la red; que son los criterios para cambiar los pesos de las conexiones, con el objetivo que esta aprenda. Se considera dos tipos de reglas, aprendizaje supervizado y no supervizado, cuya diferencia principal radica en la existencia o no de un agente externo que controle el proceso.\nRedes neuronales con aprendizajes supervisado: En este tipo de aprendizaje se tiene la participación de un agente externo o supervisor que establece la respuesta que debería tener la red a partir de una entrada específica. Este supervisor comprueba la salida de la red y si no se da la coincidencia con la deseada, se modifica los pesos de las conexiones, hasta que la salida se aproxime al valor requerido (González 2000).\nRedes neuronales con aprendizaje no supervizado: Este tipo de aprendizaje no requiere de un agente externo para ajustar los pesos de las conexiones, la red no recibe informacipon que le indique la salida deseada en función de una determinada entrada. Esto significa que no conoce si la salidad de la neurona es correcta o no, se dice que estas redes son capaces de autoorganizarse (González 2000).\nUn criterio a tener en cuenta en las reglas de aprendizaje es lo que se conoce como aprendizaje on line y off line. (González 2000) establecen que en el aprendizaje on line los pesos varían dinámicamente siempre que se ingrese nueva información al sistema; mientras que, en el aprendizaje off line, una vez que la red a aprendido, los pesos se mantienen fijos.\n\n\n1.2.4.2 Fase de Recuerdo\n\n\nPor lo general, una vez que la red a concluido su fase de aprendizaje esta se “apaga o desconecta”; es decir, pasa a un estado off line, por lo cual, los pesos, conexiones y estructura de la red se mantiene fijos y esta puede procesar nueva información.\n\n\n\n1.2.5 Clasificación de los modelos neuronales\nPor lo expresado hasta el momento se puede deducir que dependiendo del modelo de neurona que se utilice, su arquitectura, tipo de conexión, y algoritmo de aprendizaje se obtendrá distintos modelos de redes neuronales.\nEn la figura 6 se expone, a modo de resumen, la clasificación de las redes neuronales por tipo de aprendizaje y arquitectura ya expuestas anteriormente.\n\n\n\nClasificación de las redes neuronales.\n\n\nEn el caso de un Credit Scoring, los nodos de entrada representan las variables independientes \\(X\\), que son las características propias del solicitante de crédito. La respuesta de la neurona producirá una salida que representa la variable dependiente \\(Y\\), descrita anteriormente (Jiménez-Caballero 2000).\nEl método que se utilizará para encontrar los pesos de la red neuronal, del presente proyecto, es el algoritmo RPROP+ (resilient backpropagation with weight backtracking).\nTal como lo expresa (Riedmiller 1993) el algoritmo Backpropagation es el más extensamente usado para aprendizaje supervisado y redes neuronales multicapa. Desafortunadamente este puede ser muy lento para aplicaciones prácticas (Schiffmann 1994). Para superar esta dificultad se propone diversas variantes a este método como el método RPROP+, el cual es usado en este trabajo. Tanto el algoritmo Backpropagation como su variante RPROP+, son descritos a continuación.\n\n\n1.2.6 Algoritmo Backpropagation\nEl algoritmo de backpropagation es el más ampliamente usado para modelos con aprendizaje supervizado multicapa. La idea básica de este algoritmo es la siguiente:\nEn un espacio de \\(N+1\\) dimensiones, donde \\(N\\) es el número de pesos de la red, se representa una superficie que muestre el error que se genera en la red neuronal, para un determinado valor en los pesos de esta.\nEl algoritmo backpropagation hace que se vaya bajando por la superficie del error hasta lograr un mínimo, es por esta razón que la variación de un peso \\(w_{ij}\\) de la red, en una iteración, al procesar un conjunto de patrones \\(p_i\\), es proporcional al gradiente descendente (González 2000).\n\\[\n\\triangle w_{ji} = -\\alpha \\frac{\\partial E_{p}}{\\partial w_{ji}}\n\\]\nConsiderando a E la función de error, se tiene que:\n\\[\n\\frac{\\partial E_p}{\\partial w_{ji}} = \\frac{\\partial E_p}{\\partial y_{pj}}\\times \\frac{\\partial y_{pj}}{\\partial Net_{j}}\\times \\frac{\\partial Net_{j}}{\\partial w_{ji}}\n\\]\nDonde \\(w_{ji}\\) representa el peso de la neurona \\(j\\) a la reunión \\(i\\), \\(y_{pj}\\) es la salida de la neurona \\(j\\) en el patrón \\(p\\), y \\(Net_j\\) es la suma ponderada de las entradas a la neurona \\(j\\), es decir:\n\\[\nNet_j = \\sum_{i=1}^k w_{ji}\\times y_i\n\\]\n\\[\ny_{pj} = f(Net_j)\n\\]\nSiendo \\(k\\), en número de entradas de la neurona \\(j\\) y \\(f\\) la función de activación, derivable.\nEs así, que la actualización de los pesos está dada por la siguiente ecuación:\n\\[\nw_{ji}(t+1) = w_{ji}(t) - \\alpha \\frac{\\partial E_p}{\\partial w_{ji}}(t+1)\n\\]\nEs evidente que la elección de \\(\\alpha\\) tiene un efecto importante en el tiempo de convergencia del algoritmo, el cual se detiene cuando el error resulte aceptablemente pequeño para cada uno de los patrones aprendido.\n\n\n1.2.7 Algoritmo RPROP+\nUna alternativa al algoritmo de backpropagation es el resiliente backpropagation (RPROP+) en el que, en lugar de usar la magnitud de la derivada \\(\\frac{\\partial E_p}{\\partial w_{ji}}\\), presente en la ecuación \\(\\triangle w_{ji}\\), se considera únicamente su signo multiplicado por una constante. Este algoritmo tiene la ventaja de ser uno de los algoritmos de aprendizaje más rápidos (Almeida 2009).\nEl algoritmo RPROP+ consiste en los siguiente (Igel 2000): Para cada peso se introduce su valor de actualización \\(\\triangle_{ji}\\), que determina el tamaño de la actualización del peso.\n\\[\n\\left\\{\\begin{array}{cc}\\eta^+ \\times \\Delta_{ji}^{t-1}, & si ~ \\frac{\\partial E_p^{(t-1)}}{\\partial w_{ji}} \\times \\frac{\\partial E_{p}^{(t)}}{\\partial w_{ij}} &gt; 0\\\\\\eta^- \\times \\Delta_{ij}^{t-1}, & si~ \\frac{\\partial E_{p}^{(t-1)}}{\\partial w_{ij}} \\times \\frac{\\partial E_{p}^{(t)}}{\\partial w_{ij}} &lt; 0  \\\\\\Delta_{ji}^{t-1}, & caso~contrario\\end{array}\\right.\n\\]Donde \\(0 &lt; \\eta^- &lt; 1&lt; \\eta^+\\). \\(\\Delta_{ji}\\) están acotados por dos parámetros \\(\\Delta_{\\min}\\) y \\(\\Delta_{\\max}\\). Una vez obtenidos los tamaños de actualización es necesario el valor de variación de los pesos \\(\\Delta w_{ji}\\), distinguiendo dos casos.\nSi el signo de la derivada parcial no ha cambiado se tiene:\n\\[\nSi ~ \\frac{\\partial E_{p}^{(t-1)}}{\\partial w_{ji}} \\times \\frac{\\partial E_{p^{(t)}}}{\\partial w_{ji}} ≥ 0 ~ entonces ~ \\Delta w_{ji}^t = -sign\\left(\\begin{array}{c}\\frac{\\partial E_{p}^{(t)}}{\\partial w_{ji}}\\end{array}\\right) \\times \\Delta_{ji}^t\n\\]\nDonde el operador signo retorna +1 si el argumento es positivo, -1 si es negativo y 0 en otro caso. En caso de que el signo de la derivada parcial cambia, se tiene:\n\\[\nSi ~ \\frac{\\partial E_{p}^{(t-1)}}{\\partial w_{ji}} \\times \\frac{\\partial E_{p}^{(t)}}{\\partial w_{ji}} &lt; 0 ~ entonces ~ \\Delta w_{ji}^t = - \\Delta w_{ji}^{t-1} ~ y ~ \\frac{\\partial E_{p}^{(t)}}{\\partial w_{ji}} = 0\n\\]\nFinalmente se actualiza los nuevos pesos, los cuales están dados por,\n\\[\nw_{ji}(t+1) ) w_{ji}(t) + \\Delta w_{ji}(t)\n\\]La función de error que será usada para optimizar los pesos es la suma de los errores cuadráticos definida de la siguiente forma Ladino (2014) :\n\\[\nE = \\frac{1}{2}\\sum_{i=1}^n (y_i - \\hat{y_i})^2\n\\]\nDonde \\(n\\) es el número de datos en entrenamiento, observaciones, \\(y_i\\) es la salida deseada y \\(\\hat{y_i}\\) es la salida de la red.\n\n\n\n\nAllison, Paul D. 2012. Logistic Regression Using SAS: Theory and Application. SAS Press.\n\n\nAlmeida, Carlton Baugh, C. 2009. “Modelling the Dusty Universe i: Introducing the Artificial Neural Network and First Applications to Luminosity and Colour Distributions”. Monthly Notices of the Royal Astronomical Society 402 (junio). https://doi.org/10.1111/j.1365-2966.2009.15920.x.\n\n\nBAHAMÓN, RODRIGO VILLAMIL. 2013. MODELO PREDICTIVO NEURONAL PARA LA EVALUACIÓN DEL RIESGO CREDITICIO. Universidad Nacional de Colombia.\n\n\nBrío, y Alfredo Sanz Molina, Bonifacio Martín del. 2002. Redes Neuronales y Sistemas Difusos. Bogotá Colombia.\n\n\nCarranza Bravo, Paola. 2010. “INTRODUCCIÓN a LAS TÉCNICAS DE INTELIGENCIA ARTIFICIAL APLICADAS a LA GESTIÓN FINANCIERA EMPRESARIAL. Fides et Ratio - Revista de Difusión cultural y científica de la Universidad La Salle en Bolivia 4 (4): 8–15.\n\n\nFlórez, Orlando Moscote, y William Arley Rincón. 2002. ‘Modelo Logit y Probit: Un Caso de Aplicación. Universidad Santo Tomas de Colombia.\n\n\nGonzález, y Víctor José Martínez Hernando, José Ramón Hilera. 2000. Redes Neuronales Artificiales: Fundamentos, Modelos y Aplicaciones. México: Alfaomega: Ra-Ma.\n\n\nGujarati, Damodar N, Demetrio Garmendia Guerrero. 2005. Econometría. McGraw-Hill.\n\n\nGutierrez Girault, Matias Alfredo. 2007. Modelos de Credit Scoring: Qué, Cómo, Cuándo y Para Qué. Munich Personal RePEc Archive.\n\n\nIgel, y Michael Hüsken, Christian. 2000. “Improving the Rprop Learning Algorithm”.\n\n\nJiménez-Caballero, y Ramón Jesús Ruiz Martínez, José Luis. 2000. “Las Redes Neuronales En Su Aplicación a Las Finanzas”. Banca y finanzas: Revista profesional de gestión financiera, núm. 54: 19–27.\n\n\nLadino, Becerra Iván Camilo. 2014. “Comparación de Modelos de Riesgo de Crédito: Modelos Logísticos y Redes Neuronales”. Pontifica Universidad Javeriana Facultad de Ciencias Economicas y Administrativas maestria en economía.\n\n\nRiedmiller, y Heinrich Braun, Martin. 1993. “A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm”. En, 1:586–91 vol.1. https://doi.org/10.1109/ICNN.1993.298623.\n\n\nSchiffmann, M Joost, W. 1994. “Optimization of the Backpropagation Algorithm for Training Multilayer Perceptrons”. diciembre.\n\n\nTudela, y Gimmy Nardó., Sanjinés. 2011. Análisis y Pronóstico de La Demanda de Potencia Eléctrica En Bolivia: Una Aplicación de Redes Neuronales. Revista Latinoamericana de Desarrollo Económico.\n\n\nVelasco, Manuel Salas. 1996. “La Regresión Logística . Una Aplicación a La Demanda de Estudios Universitarios.” ESTADÍSTICA ESPAÑOLA 38 (141): 193–217.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Credit Scoring</span>"
    ]
  },
  {
    "objectID": "modelizacion.html",
    "href": "modelizacion.html",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "",
    "text": "2.1 Prueba Dickey - Fuller aumentada\nLa prueba de Dickey - Fuller aumentada permite corroborar la estacionariedad de una serie de tiempo. Cuando una serie no estacionaria presenta al menos una raíz unitaria, por lo que se busca contrastar la siguiente hipótesis (Santos 2008):\nSe rechaza \\(H_0\\) si:\nValor absoluto (Estadístico de la prueba (ADF)) \\(&gt;\\) valores críticos de la prueba \\((1\\%, 5\\%, 10\\%)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#prueba-dickey---fuller-aumentada",
    "href": "modelizacion.html#prueba-dickey---fuller-aumentada",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "",
    "text": "\\(H_0:\\) la serie tiene raíz unitaria\n\\(H_a:\\) la serie es estacionaria",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#muestreo-aleatorio-simple",
    "href": "modelizacion.html#muestreo-aleatorio-simple",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.2 Muestreo Aleatorio Simple",
    "text": "2.2 Muestreo Aleatorio Simple\nEl tamaño de muestra es necesario para estimar \\(p\\) (proporción poblacional) con un límite para el error de estimación \\(B\\), está dado por (Scheaffer 2013):\n\\[\nn = \\frac{Npq}{(N - 1)D + pq} ~ donde: ~ q = 1 - p ~ y ~ D = \\frac{B^2}{4}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#roll-rate",
    "href": "modelizacion.html#roll-rate",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.3 Roll Rate",
    "text": "2.3 Roll Rate\nImplica comparar el peor atraso en un \\(X\\) número de meses, con los posteriores \\(X\\) meses. Y así, calcular el porcentaje de operaciones o clientes que mantienen, mejoran o empeoran su comportamiento, en distintos rangos de atraso. El propósito es identificar el punto de no retorno: es decir, el nivel de atraso en el cual, una operación es considerada como insalvable (Siddiqi 2006).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#valor-de-información-iv",
    "href": "modelizacion.html#valor-de-información-iv",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.4 Valor de Información (IV)",
    "text": "2.4 Valor de Información (IV)\nEl valor de información es un valor numérico que permite cuantificar el poder de predicción de una variable independiente. El mismo, funciona con variables categóricas. Se calcula a partir de la siguiente expresión:\n\\[\nIV = \\sum_{i=1}^n \\left(\\begin{array}{c}\\frac{b_i}{b} - \\frac{m_i}{m}\\end{array}\\right) \\times \\ln \\left(\\begin{array}{c}\\frac{b_i/b}{m_i/m}\\end{array}\\right)\n\\]\nDonde, \\(n\\) es el número de categorías en la variable independiente, \\(b_i\\) y \\(m_i\\) es el número de buenos y malos clientes dentro de la categoría \\(i\\). Y \\(b\\) y \\(m\\): el número total de buenos y malos clientes en el periodo de modelo, respectivamente.\nIntuitivamente, mientras más grande sea el valor de IV, más predictiva será la variable independiente categorizada. Sin embargo, las variables con valores superiores a 0.5 deberían ser revisadas pues puede darse el caso de sobreestimación (Siddiqi 2006).\nUna regla propuesta por (Siddiqi 2006)\n\nRegla valor de información IV\n\n\nValor IV\nNivel de Predicción\n\n\n\n\n\\(IV &lt; 0.02\\)\nNo predictivo\n\n\n\\(0.02 ≤ IV ≤ 0.1\\)\nDébil\n\n\n\\(0.1 ≤ IV ≤ 0.3\\)\nMedio\n\n\n\\(IV &gt; 0.3\\)\nFuerte",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#backward-stepwise-y-criterio-de-información-de-akaike-aic",
    "href": "modelizacion.html#backward-stepwise-y-criterio-de-información-de-akaike-aic",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.5 Backward Stepwise y Criterio de Información de Akaike (AIC)",
    "text": "2.5 Backward Stepwise y Criterio de Información de Akaike (AIC)\nLa técnica de pasos hacia atras (Backward Stepwise) consiste en introducir en el modelo todas las variables e ir excluyendo una tras otra según algún criterio de evaluación (Moral 2006). En este caso, se utiliza el AIC como críterio de selección de variables, considerando aquellas que logren el menor valor de AIC.\nEl criterio de información de Akaike penaliza los modelos con muchos parámetros y busca determinar la significancia de incluir algunos parámetros en el modelo (Sanchez 2012). Este criterio se define como sigue:\nPara un conjunto de \\(m\\) modelos, de tal forma que,\n\\[\nM_j^m \\supset M_{j-1}^{m-1} \\supset . . . \\supset M_{j-i}^1\n\\]\nDonde, \\(j &gt; i\\), \\(i &gt; 0\\) y los subíndices denotan el número de variables en cada modelo. Se busca elegir aquel valor de \\(j\\) que minimice la siguiente expresión,\n\\[\nAIC = -2\\log L + 2k\n\\]\nSiendo, \\(L\\) es la función de máxima verosimilitud, que se define como:\n\\[\nL = -\\frac{n}{2}\\log 2\\pi - \\frac{n}{2}\\log \\sigma^2 - \\frac{1}{2}\\sum_{t=1}^n \\frac{e_t^2}{\\sigma^2}\n\\]\nDonde, \\(k\\) es igual al número de parámetros del modelo, \\(n\\) corresponde al número de datos para la construcción de este y \\(\\sigma^2\\) el promedio de los residuales \\(e_t\\) al cuadrado. Como se puede observar, AIC penaliza modelos según su desviación de los datos reales, siendo el mejor modelo aque que manifieste el valor más pequeño entre todos los modelos evaluados, siendo este el que mejor ajusta a los datos (Sanchez 2012).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#estadístico-de-wald",
    "href": "modelizacion.html#estadístico-de-wald",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.6 Estadístico de Wald",
    "text": "2.6 Estadístico de Wald\nPara corroborar la significancia de los coeficientes de un modelo logit, se contrasta la siguiente hipótesis nula:\n\\[\nH_0: \\beta_i = 0\n\\]Considerando a \\(\\beta_i\\) como el coeficiente estimado correspondiente a la variable independient \\(x_i\\).\nAsí, se cuenta con el estadístico de Wald (Wasserman 2010): Sea \\(\\theta\\) un parámetro escalar, \\(\\hat{\\theta}\\) un estimador de \\(\\theta\\) y sea \\(\\hat{se}\\) el error estándar estimado de \\(\\hat{\\theta}\\). Considerar probar \\(H_0: \\theta = \\theta_0\\) vs \\(H_1: \\theta ≠ \\theta_0\\). Se asume que \\(\\hat{\\theta}\\) es asintoticamente normal,\n\\[\n\\frac{\\sqrt{n}(\\hat{\\theta} - \\theta_0)}{\\hat{se}} \\longrightarrow N(0,1)\n\\]\nCon un nivel de significancia de \\(\\alpha\\), la prueba de Wald establece: Se rechaza \\(H_0\\) cuando \\(|W| &gt; z_{\\alpha/2}\\) donde,\n\\[\nW = \\frac{\\hat{\\theta} - \\theta_0}{\\hat{se}}\n\\]\nEn este caso, \\(\\theta_0 = 0\\), por lo cual el estadístico de Wald se simplifica a\n\\[\nW = \\frac{\\hat{\\beta}}{\\hat{se}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#gvif-factor-de-inflación-de-la-varianza-generalizado",
    "href": "modelizacion.html#gvif-factor-de-inflación-de-la-varianza-generalizado",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.7 GVIF: Factor de inflación de la varianza generalizado",
    "text": "2.7 GVIF: Factor de inflación de la varianza generalizado\nGVIF es una medida de cuanto de la varianza del coeficiente estimado \\(\\beta_j\\) está inflado por la existencia de correlación entre las variables independientes del modelo. Se usa comúnmente cuando se tiene variables categóricas con más de dos valores posibles o con variables polinomiales (Fox 2003), está dado por,\n\\[\nGVIF_i = \\frac{\\det R_i \\times \\det R_{-i}}{\\det R}\n\\]\nSiendo \\(\\det R_i\\) el determinante de la matriz de correlación sobre las columnas de la variable \\(i\\), \\(\\det R_{-i}\\) el determinante de la matriz de correlación sobre las columnas del resto de variables del modelo, distintas a la variable \\(i\\) y \\(\\det R\\) el determinante de la matriz completa de correlación. Cuando el número de coeficientes de cada variable es uno, el GVIF coincide con VIF (factor de inflación de la varianza $1/(1-R_i^2), siendo ~ \\(R^2\\) ~ el ~ coeficiente ~ de ~ determinacón)$. A pesar, de no tener una regla formal, generalmente se acepta que valores de GVIF superiores a 10 puede ser perjudicial (Yoo 2014).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#estadístico-de-kolmogorov---smirnov-ks",
    "href": "modelizacion.html#estadístico-de-kolmogorov---smirnov-ks",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.8 Estadístico de Kolmogorov - Smirnov (KS)",
    "text": "2.8 Estadístico de Kolmogorov - Smirnov (KS)\nEl estadístico de Kolmogorov Smirnov consiste en medir cuan distintas son las funciones de distribución de buenos y malos clientes para cada valor de puntaje score.\nEl valor del estadístico está dado por (Rezac 2011),\n\\[\nKS = \\max\\left(\\begin{array}{c}P_b(i) - P_g(i)\\end{array}\\right)\n\\]\nDonde:\n\\(\\textbf{i}:\\) es el valor de score, en el rango \\(L - H\\), que es, \\(L ≤ i ≤ H\\).\n\\(\\textbf{P}_\\textbf{g}(\\textbf{i})\\), \\(\\textbf{P}_\\textbf{b}(\\textbf{i}):\\) Proporción de buenos y malos con score menor o igual a \\(i\\), en la población.\n\\[\nP_g(i) = \\frac{N_g(i)}{N_g} = \\sum_{j = L}^i p_g(j)\n\\]\n\\[\nP_b(i) = \\frac{N_b(i)}{N_b} = \\sum_{j = L}^i p_b(j)\n\\]\nCon:\n\\(N_g:\\) El total de buenos en la población.\n\\(N_b:\\) El total de malos en la población.\n\\(N_g(i), N_b(i):\\) El número de buenos y malos en la población con scores menores o iguales a \\(i\\).\n\\[\nN_g(i) = \\sum_{j = L}^{i} n_g(j)\n\\]\n\\[\nN_b(i) = \\sum_{j=L}^i n_b(j)\n\\]\n\\(p_g(i), p_b(i):\\) Es la proporción de buenos con score \\(i\\) y malos con score \\(i\\) en la población.\n\\[\np_g(i) = \\frac{n_g(i)}{N_g}\\hspace{1cm} \\frac{n_b(i)}{N_b}\n\\]\nFinalmente, \\(n_g(i)\\) y \\(n_b(i)\\) el número de buenos casos y malos con score \\(i\\), en una población.\nEl estadístico puede ser usado para medir la capacidad de clasificiación de un modelo, tomando valores entre 0 y 1. Se considera que un modelo con un KS menor a 20% debe ser cuestionado y mayor a 70% sea, probablemente, muy bueno para ser cierto.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#coeficiente-de-gini",
    "href": "modelizacion.html#coeficiente-de-gini",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.9 Coeficiente de GINI",
    "text": "2.9 Coeficiente de GINI\nEl coeficiente de GINI es un estadístico usado para medir cuan bien el modelo scoring distingue entre los buenos y malos clientes, toma valores entre 0 y 1, considerando que, si el coeficiente de Gini es igual a 1, entonces el modelo separa perfectamente a bueno y malos.\nEl estadístico está dado por la siguiente ecuación:\n\\[\nGini = 1 - \\sum_{i = L}^{H^{\\prime}} \\left(\\begin{array}{c}P_b(i+1) - P_b(i)\\end{array}\\right)\\left(\\begin{array}{c}P_g(i+1) + P_g(i)\\end{array}\\right)  \n\\]\nDonde:\n\\(\\textbf{i}:\\) es el valor de score, en el rango \\(L - H\\), que es, \\(L ≤ i ≤ H\\).\n\\(\\textbf{P}_\\textbf{g}(\\textbf{i}), \\textbf{P}_\\textbf{b}(\\textbf{i}):\\) Proporción de buenos y malos con score menor o igual a \\(i\\), en la población, respectivamente.\nSe considera que para modelos de originación, un coeficiente de Gini menor a 35% es sospechoso y mayor a 50% es más que satisfactorio.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#matriz-de-confusión-error-sensibilidad-y-especificidad",
    "href": "modelizacion.html#matriz-de-confusión-error-sensibilidad-y-especificidad",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.10 Matriz de confusión: error, sensibilidad y especificidad",
    "text": "2.10 Matriz de confusión: error, sensibilidad y especificidad\nUna forma simple de evaluar la predictividad de un modelo, es calculando el porcentaje de clientes que este clasifica de forma correcta. Este porcentaje de clasificación es derivado, de la matriz de confusión, la cual es construida de la siguiente forma:\n\nElegir un punto de corte, para los valores de score obtenidos.\nClasificar a todas las operaciones o clientes con un valor de score por debajo del punto de corte, como malos esperados. Y a los que tiene un valor de score por encima del punto de corte, como buenos esperados.\nConstruir una tabla cruzada entre la clasificación real u original de bueno/malo y la de bueno/malo esperado, obtenida en el paso anterior.\nCalcular las diferentes ratios que pueden ser obtenidos del modelo, como error, valor de sensibilidad y especificidad.\n\nLos casos correctamente clasificados son denominados como verdaderos positivos (buenos) y verdaderos negativos (malos). Si no son bien clasificados se tiene a los falsos positivos (malos que son clasificados como buenos) y a los falsos negativos (buenos que son clasificados como malos).\nAdemás, se define como sensibilidad y especificidad, a la habilidad del modelo de catalogar correctamente al cliente bueno y malo, respectivamente. La forma general de la matriz de confusión es mostrada en la siguiente tabla:\n\nY en la siguiente tabla se expone los indicadores de eficiencia, que serán usados para comparar los modelos desarrollados, construidos a partir de la matriz de confusión.\n\nUna forma de obtener el punto de corte que permita nivelar la predicción correcta de buenos y malos es hacer uso del índice de Youden, que está dado por:\n\\[\nindice~de~Youden(YI) = \\max(Sensibilidad + Especificidad -  1)\n\\]\nEn una curva ROC, que será definida en el siguiente apartado, el índice de Youden es la distancia vertical máxima ente la curva y la diagonal. Siendo el punto de corte óptimo, aquel en el cual se alcanza el valor de YI (Cadarso Suárez 2010) .",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "modelizacion.html#estadístico-auroc",
    "href": "modelizacion.html#estadístico-auroc",
    "title": "2  Conceptos del Proceso de Modelización",
    "section": "2.11 Estadístico AUROC",
    "text": "2.11 Estadístico AUROC\nEs una medida de performance cercanamente relacionada al coeficiente Gini y midel el área entre la curva y la diagonal conformada en la gráfica de sensibilidad vs (1 - especificidad), comúnmente llamada Curva ROC, para el total de los valores de probabilidad. Permite medir la eficacia predictiva de un modelo, evaluando gráficamente la capacidad de este para discriminar entre buenos y malos.\nLa relación entre el estadístico AUROC y el coeficiente de Gini es el que se muestra a continuación Till (2001)\n\\[\nAUROC = \\frac{Gini + 1}{2}\n\\]\nEl valor de AUROC varía entre 0 y 1. Un valor de 0.5 implicaría que el modelo es igual a hacer una clasificación aleatoria para catalogar a un cliente como bueno o malo, un valor de 1 significa que las clasificaciones son perfectamente correctas y un valor de 0 implica que las mismas son totalmente incorrectas. Tal como expresa (Siddiqi 2006) el valor del estadístico AUROC deber estar entre 0.5, y un valor superior a 0.7 se considera adecuado.\n\n\n\n\nCadarso Suárez, Carmen Maria. 2010. Metodología ROC En La Evaluación de Medidas Antropométricas Como Marcadores de La Hipertensión Arterial. Universidad de Santiago de Compostela.\n\n\nFox, John. 2003. Linear Models Problems. Canada: McMaster Universrity.\n\n\nMoral, Irene. 2006. Modelos de Regresión: Lineal Simple y Regresión Logística. Revista Seden, el 3 de diciembre de 2006.\n\n\nRezac, y František Řezáč, Martin. 2011. How to Measure the Quality of Credit Scoring Models. Czech Journal of Economics; Finance.\n\n\nSanchez, Paola. 2012. Una Nueva Metodología de Entrenamiento de Redes Neuronales y Sus Implicaciones En La Seleción de Modelos. Universidad Nacional de Colombia.\n\n\nSantos, Holger Capa. 2008. Un Primer Curso En Series Temporales. Primera. Quito.\n\n\nScheaffer, William Mendenhall, Richard L. 2013. Elementos de Muestreo. Madrid (España): Paraninfo.\n\n\nSiddiqi, Naeem. 2006. Credit Risk Scorecards: Developing and Implementing Intelligent Credit Scoring. Hoboken. N. J: Wiley.\n\n\nTill, D. Handall y. 2001. “Statistical Classification Methods in Consumer CreditScoring: A Review”. Journal of the Royal Statistical Society. Series A (Statistics in Society).\n\n\nWasserman, Larry. 2010. All of Statistics: A Concise Course in Statistical Inference. Springer Publishing Company, Incorporated.\n\n\nYoo, Robert Mayberry, Wonsuk. 2014. A Study of Effects of MultiCollinearity in the Multivariable Analysis. International Journal of applied science; technology.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Conceptos del Proceso de Modelización</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allison, Paul D. 2012. Logistic Regression Using SAS: Theory and\nApplication. SAS Press.\n\n\nAlmeida, Carlton Baugh, C. 2009. “Modelling the Dusty Universe\ni: Introducing the Artificial Neural Network and First Applications to\nLuminosity and Colour Distributions”. Monthly Notices of the\nRoyal Astronomical Society 402 (junio).\nhttps://doi.org/10.1111/j.1365-2966.2009.15920.x.\n\n\nBAHAMÓN, RODRIGO VILLAMIL. 2013. MODELO PREDICTIVO NEURONAL PARA LA\nEVALUACIÓN DEL RIESGO CREDITICIO. Universidad Nacional de Colombia.\n\n\nBrío, y Alfredo Sanz Molina, Bonifacio Martín del. 2002. Redes\nNeuronales y Sistemas Difusos. Bogotá Colombia.\n\n\nCadarso Suárez, Carmen Maria. 2010. Metodología ROC En La Evaluación\nde Medidas Antropométricas Como Marcadores de La Hipertensión\nArterial. Universidad de Santiago de Compostela.\n\n\nCarranza Bravo, Paola. 2010. “INTRODUCCIÓN a LAS TÉCNICAS DE\nINTELIGENCIA ARTIFICIAL APLICADAS a LA GESTIÓN FINANCIERA\nEMPRESARIAL. Fides et Ratio - Revista de Difusión cultural y\ncientífica de la Universidad La Salle en Bolivia 4 (4): 8–15.\n\n\nFlórez, Orlando Moscote, y William Arley Rincón. 2002. ‘Modelo Logit\ny Probit: Un Caso de Aplicación. Universidad Santo Tomas de\nColombia.\n\n\nFox, John. 2003. Linear Models Problems. Canada: McMaster\nUniversrity.\n\n\nGonzález, y Víctor José Martínez Hernando, José Ramón Hilera. 2000.\nRedes Neuronales Artificiales: Fundamentos, Modelos y\nAplicaciones. México: Alfaomega: Ra-Ma.\n\n\nGujarati, Damodar N, Demetrio Garmendia Guerrero. 2005.\nEconometría. McGraw-Hill.\n\n\nGutierrez Girault, Matias Alfredo. 2007. Modelos de Credit Scoring:\nQué, Cómo, Cuándo y Para Qué. Munich Personal RePEc Archive.\n\n\nIgel, y Michael Hüsken, Christian. 2000. “Improving the Rprop\nLearning Algorithm”.\n\n\nJiménez-Caballero, y Ramón Jesús Ruiz Martínez, José Luis. 2000.\n“Las Redes Neuronales En Su Aplicación a Las\nFinanzas”. Banca y finanzas: Revista profesional de gestión\nfinanciera, núm. 54: 19–27.\n\n\nLadino, Becerra Iván Camilo. 2014. “Comparación de Modelos de\nRiesgo de Crédito: Modelos Logísticos y Redes Neuronales”.\nPontifica Universidad Javeriana Facultad de Ciencias Economicas y\nAdministrativas maestria en economía.\n\n\nLean Yu, Kin Keung Lai, Shouyang Wang. 2008. Bio-Inspired Credit\nRisk Analysis: Computational Intelligence with Support Vector\nMachines. Springer Link.\n\n\nMoral, Irene. 2006. Modelos de Regresión: Lineal Simple y Regresión\nLogística. Revista Seden, el 3 de diciembre de 2006.\n\n\nRezac, y František Řezáč, Martin. 2011. How to Measure the Quality\nof Credit Scoring Models. Czech Journal of Economics; Finance.\n\n\nRiedmiller, y Heinrich Braun, Martin. 1993. “A Direct Adaptive\nMethod for Faster Backpropagation Learning: The RPROP\nAlgorithm”. En, 1:586–91 vol.1.\nhttps://doi.org/10.1109/ICNN.1993.298623.\n\n\nSamsul Islam, Fei Li, Lin Zhou. 2009. Application of Artificial\nIntelligence (Artificial Neural Network) to Assess Credit Risk: A\nPredictive Model for Credit Card Scoring. Springer Link.\n\n\nSanchez, Paola. 2012. Una Nueva Metodología de Entrenamiento de\nRedes Neuronales y Sus Implicaciones En La Seleción de Modelos.\nUniversidad Nacional de Colombia.\n\n\nSantos, Holger Capa. 2008. Un Primer Curso En Series\nTemporales. Primera. Quito.\n\n\nScheaffer, William Mendenhall, Richard L. 2013. Elementos de\nMuestreo. Madrid (España): Paraninfo.\n\n\nSchiffmann, M Joost, W. 1994. “Optimization of the\nBackpropagation Algorithm for Training Multilayer\nPerceptrons”. diciembre.\n\n\nSiddiqi, Naeem. 2006. Credit Risk Scorecards: Developing and\nImplementing Intelligent Credit Scoring. Hoboken. N. J: Wiley.\n\n\nTill, D. Handall y. 2001. “Statistical Classification Methods\nin Consumer CreditScoring: A Review”. Journal of the Royal\nStatistical Society. Series A (Statistics in Society).\n\n\nTudela, y Gimmy Nardó., Sanjinés. 2011. Análisis y Pronóstico de La\nDemanda de Potencia Eléctrica En Bolivia: Una Aplicación de Redes\nNeuronales. Revista Latinoamericana de Desarrollo Económico.\n\n\nVelasco, Manuel Salas. 1996. “La Regresión Logística . Una\nAplicación a La Demanda de Estudios Universitarios.”\nESTADÍSTICA ESPAÑOLA 38 (141): 193–217.\n\n\nWasserman, Larry. 2010. All of Statistics: A Concise Course in\nStatistical Inference. Springer Publishing Company, Incorporated.\n\n\nYoo, Robert Mayberry, Wonsuk. 2014. A Study of Effects of\nMultiCollinearity in the Multivariable Analysis. International\nJournal of applied science; technology.",
    "crumbs": [
      "References"
    ]
  }
]